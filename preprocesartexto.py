import os
import string
# import fontstyle
# import tkinter
import unicodedata
import nltk
from nltk.tokenize import word_tokenize
from nltk.corpus import stopwords
from dotenv import load_dotenv
import pandas as pd
import plotly.graph_objects as go

nltk.download('punkt')
nltk.download('stopwords')

stopWords = set(stopwords.words('spanish'))

# Ajustar las opciones de visualizaciÃ³n en terminal
pd.set_option('display.max_rows', None)  # Muestra todas las filas
pd.set_option('display.max_columns', None)  # Muestra todas las columnas
pd.set_option('display.width', None)  # Ajusta el ancho de la visualizaciÃ³n
pd.set_option('display.max_colwidth', None)  # Muestra el contenido completo de las columnas

# Cargar variables de entorno
load_dotenv()
PATH_SUBJECTSTRAIN = os.getenv('PATH_SUBJECTSTRAIN')
PATH_TRAIN = os.getenv('PATH_TRAIN')
PATH_CSVLINKEDFILES = os.getenv('PATH_CSVLINKEDFILES')

# Declarar de dict para guardar los subjects preprocesados
dataArray = {
    'Subject': [],
    'id_message': [],
    'message': [],
    'preproccedMessage': [],
    'date': [],
    'label': []
}

# Declarar array para contar las palabras
wordCount = {}

# Declarar array para ver las palabras y su subject asociado
wordStrange = {}

# Declarar array de stop words no contenidas en nltk
stop_words = stopWords.union(
    [
        "a", "al", "algo", "algunas", "algunos", "ante", "antes", "como", "con", "contra", "cual", "cuando", "de",
        "del", "desde",
        "donde", "durante", "e", "el", "ella", "ellas", "ellos", "en", "entre", "era", "erais", "Ã©ramos", "eran",
        "eras", "eres",
        "es", "esa", "esas", "ese", "esos", "esta", "estaba", "estabais", "estÃ¡bamos", "estaban", "estabas", "estad",
        "estada",
        "estadas", "estado", "estados", "estamos", "estando", "estar", "estaremos", "estarÃ¡", "estarÃ¡n", "estarÃ¡s",
        "estarÃ©",
        "estarÃ©is", "estarÃ­a", "estarÃ­ais", "estarÃ­amos", "estarÃ­an", "estarÃ­as", "estas", "este", "estemos", "esto",
        "estos",
        "estoy", "estuve", "estuviera", "estuvierais", "estuviÃ©ramos", "estuvieran", "estuvieras", "estuvieron",
        "estuviese",
        "estuvieseis", "estuviÃ©semos", "estuviesen", "estuvieses", "estuvimos", "estuviste", "estuvisteis",
        "estuviÃ©ramos",
        "estuviÃ©semos", "estuvo", "ex", "excepto", "fue", "fuera", "fuerais", "fuÃ©ramos", "fueran", "fueras", "fueron",
        "fuese",
        "fueseis", "fuÃ©semos", "fuesen", "fueses", "fui", "fuimos", "fuiste", "fuisteis", "ha", "habÃ­a", "habÃ­ais",
        "habÃ­amos",
        "habÃ­an", "habÃ­as", "habÃ©is", "habida", "habidas", "habido", "habidos", "habiendo", "habrÃ¡", "habrÃ¡n", "habrÃ¡s",
        "habrÃ©",
        "habrÃ©is", "habremos", "habrÃ­a", "habrÃ­ais", "habrÃ­amos", "habrÃ­an", "habrÃ­as", "habÃ©is", "habÃ­a", "habÃ­ais",
        "habÃ­amos",
        "habÃ­an", "habÃ­as", "hace", "haceis", "hacemos", "hacen", "hacer", "hacerlo", "haces", "hacia", "haciendo",
        "hago",
        "han", "has", "hasta", "hay", "haya", "hayamos", "hayan", "hayas", "he", "hecho", "hemos", "hube", "hubiera",
        "hubierais",
        "hubiÃ©ramos", "hubieran", "hubieras", "hubieron", "hubiese", "hubieseis", "hubiÃ©semos", "hubiesen", "hubieses",
        "hubimos",
        "hubiste", "hubisteis", "hubiÃ©ramos", "hubiÃ©semos", "hubo", "la", "las", "le", "les", "lo", "los", "me", "mi",
        "mis",
        "mucho", "muchos", "muy", "mÃ¡s", "mÃ­", "mÃ­a", "mÃ­as", "mÃ­o", "mÃ­os", "nada", "ni", "ningÃºn", "ninguna",
        "ningunas",
        "ninguno", "ningunos", "no", "nos", "nosotras", "nosotros", "nuestra", "nuestras", "nuestro", "nuestros",
        "nunca",
        "os", "otra", "otras", "otro", "otros", "para", "parecer", "pero", "poca", "pocas", "poco", "pocos", "podÃ©is",
        "podemos",
        "poder", "podrÃ­a", "podrÃ­amos", "podrÃ­an", "podrÃ­as", "poner", "por", "porque", "primero", "puede", "pueden",
        "puedo",
        "pues", "que", "quÃ©", "querer", "quiÃ©n", "quienes", "quiere", "quiÃ©nes", "quiso", "saber", "se", "sÃ©", "ser",
        "si",
        "sÃ­", "siendo", "sin", "sino", "so", "sobre", "sois", "solamente", "solo", "sÃ³lo", "somos", "son", "soy", "su",
        "sus", "suya", "suyas", "suyo", "suyos", "sÃ­", "tambiÃ©n", "tanto", "te", "tendrÃ©", "tendrÃ©is", "tendremos",
        "tendrÃ­a",
        "tendrÃ­ais", "tendrÃ­amos", "tendrÃ­an", "tendrÃ­as", "tened", "tenemos", "tener", "tenga", "tengamos", "tengan",
        "tengas", "tengo", "tenÃ­a", "tenÃ­ais", "tenÃ­amos", "tenÃ­an", "tenÃ­as", "ti", "tiene", "tienen", "tienes",
        "todo",
        "todos", "tu", "tus", "tuve", "tuviera", "tuvierais", "tuviÃ©ramos", "tuvieran", "tuvieras", "tuvieron",
        "tuviese",
        "tuvieseis", "tuviÃ©semos", "tuviesen", "tuvieses", "tuvimos", "tuviste", "tuvisteis", "tuviÃ©ramos",
        "tuviÃ©semos",
        "tuvo", "tuya", "tuyas", "tuyo", "tuyos", "un", "una", "uno", "unos", "usa", "usamos", "usan", "usar", "usas",
        "uso", "usted", "ustedes", "va", "vais", "valor", "vamos", "van", "varias", "varios", "vaya", "veces", "ver",
        "verdad", "verdadera", "verdadero", "vosotras", "vosotros", "voy", "vuestra", "vuestras", "vuestro", "vuestros",
        "y", "ya", "yo", "Ã©l", "Ã©ramos", "Ã©sa", "Ã©sas", "Ã©se", "Ã©sos", "Ã©sta", "Ã©stas", "Ã©ste", "Ã©stos", "Ãºltima",
        "Ãºltimas",
        "Ãºltimo", "Ãºltimos"
    ]
)

# Declarar array de signos de puntuacion
puntuacion = ['___', 'âœ¦', '...', 'â€œ', 'Â«', 'âœ—', 'Â¿', 'Â»', 'â£', '``', 'Â°', 'â”']

# Declarar diccionario de emojis
emojis = {
    "ğŸ™‹â€â™€": "mujer con la mano levantada",
    "ğŸƒğŸ¾â€â™€": "mujer corriendo: tono de piel oscuro medio",
    "ğŸ¤·â€â™€": "mujer encogida de hombros",
    "ğŸ«¡": "hola",
    "ğŸ‹â€â™‚": "persona levantando pesas signo masculino",
    "ğŸ‡´": "la letra o mayuscula cirilo",
    "ğŸ’†â€â™€": "mujer recibiendo masaje",
    "ğŸ™†â€â™€": "mujer haciendo el gesto de de acuerdoï¸",
    "2âƒ£": "teclas 2",
    "ğŸ¤¦ğŸ»â€â™€": "mujer con la mano en la frente tono de piel claro",
    "ğŸ¤¦â€â™€": "mujer con la mano en la frente",
    "ğŸ« ": "estoy derretido de felicidad",
    "ğŸ‡¨": "la letra c",
    "ğŸ™‹ğŸ»â€â™€": "mujer con la mano levantada tono de piel claro",
    "ğŸ™‹ğŸ½â€â™€": "mujer con la mano levantada tono de piel medio",
    "ğŸ¤¸ğŸ»â€â™€": "mujer haciendo voltereta lateral tono de piel claro",
    "ğŸ§šâ€â™€": "hada hembra",
    "ğŸ‘¨â€âš•": "profesional sanitario hombre",
    "1âƒ£": "teclas 1",
    "ğŸ¤¦â€â™‚": "hombre con la mano en la frente",
    "ğŸ¤¦ğŸ¼â€â™€": "mujer con la mano en la frente tono de piel claro medio",
    "ğŸ¤·ğŸ»â€â™€": "mujer encogida de hombros tono de piel claro",
    "ğŸ™‹ğŸ¼â€â™€": "mujer con la mano levantada tono de piel claro medio",
    "3âƒ£": "teclas 3"
}

# Declarar diccionario para corregir las palabras con una fuente diferente
fontsWords = {
    # Primer set
    "á´€": 'A',
    "á´…": 'D',
    "á´‡": 'E',
    "Ò“": 'F',
    "Éª": 'I',
    "á´": 'M',
    "É´": 'N',
    "á´": 'O',
    "Ê€": 'R',
    "s": 'S',
    "á´›": 'T',
    "á´ ": 'V',
    "Ê": 'Y',
    # Segundo set
    "ğ´": 'A',
    "ğ‘": 'a',
    "ğ‘Ì€": 'a',
    "ğ‘": 'b',
    "ğ¶": 'C',
    "ğ‘": 'c',
    "ğ·": 'D',
    "ğ‘‘": 'd',
    "ğ¸": 'E',
    "ğ‘’": 'e',
    "ğ‘“": 'f',
    "ğ‘”": 'g',
    "ğ»": 'H',
    "â„": 'h',
    "ğ‘–": 'i',
    "ğ‘—": 'j',
    "ğ‘˜": 'k',
    "ğ¿": 'L',
    "ğ‘™": 'l',
    "ğ‘€": 'M',
    "ğ‘š": 'm',
    "ğ‘": 'N',
    "ğ‘›": 'n',
    "ğ‘œ": 'o',
    "ğ‘œÌ": 'o',
    "ğ‘ƒ": 'P',
    "ğ‘": 'p',
    "ğ‘„": 'Q',
    "ğ‘": 'q',
    "ğ‘…": 'R',
    "ğ‘Ÿ": 'r',
    "ğ‘†": 'S',
    "ğ‘ ": 's',
    "ğ‘‡": 'T',
    "ğ‘¡": 't',
    "ğ‘ˆ": 'U',
    "ğ‘¢": 'u',
    "ğ‘£": 'v',
    "ğ‘¥": 'x',
    "ğ‘¦": 'y',
    "ğ‘§": 'z',
    # Tercer set
    "ğ€": 'A',
    "ğ": 'B',
    "ğ„": 'E',
    "ğ‡": 'H',
    "ğˆ": 'I',
    "ğ‹": 'L',
    "ğŒ": 'M',
    "ğ": 'N',
    "ğ": 'O',
    "ğ": 'P',
    "ğ‘": 'R',
    "ğ’": 'S',
    "ğ˜": 'Y',

    "": 'A',
    "": 'a',
    "": 'B',
    "": 'b',
    "": 'C',
    "": 'c',
    "": 'D',
    "": 'd',
    "": 'E',
    "": 'e',
    "": 'F',
    "": 'f',
    "": 'G',
    "": 'g',
    "": 'H',
    "": 'h',
    "": 'I',
    "": 'i',
    "": 'J',
    "": 'j',
    "": 'K',
    "": 'k',
    "": 'L',
    "": 'l',
    "": 'M',
    "": 'm',
    "": 'N',
    "": 'n',
    "": 'Ã‘',
    "": 'Ã±',
    "": 'O',
    "": 'o',
    "": 'P',
    "": 'p',
    "": 'Q',
    "": 'q',
    "": 'R',
    "": 'r',
    "": 'S',
    "": 's',
    "": 'T',
    "": 't',
    "": 'U',
    "": 'u',
    "": 'V',
    "": 'v',
    "": 'W',
    "": 'w',
    "": 'X',
    "": 'x',
    "": 'Y',
    "": 'y',
    "": 'Z',
    "": 'z',
}

def readJSONFiles():
    # Obtener el nombre del archivo para cada archivo en la ruta TRAIN
    for name_file in os.listdir(PATH_SUBJECTSTRAIN):
        # leer JSON
        file = pd.read_json(f"{PATH_SUBJECTSTRAIN}/{name_file}")
        preprocesstext(file, name_file)


# FunciÃ³n para leer los archivos JSON y crear un DataFrame con el nombre del archivo y
# los datos asociados

# FunciÃ³n para leer las etiquetas
def readTXT():
    trainLabel = pd.read_csv(PATH_TRAIN)
    return trainLabel

# Preprocesar texto
def preprocesstext(file, name_file):
    trainLabel = readTXT()
    i = 0

    # Agregar la columna subject
    file.insert(0, 'Subject', name_file)
    # Agregar la columna para el texto preprocesado
    file.insert(3, 'preproccedMessage', " ")

    # Obtener el label para un subject especifico
    specLabel = trainLabel[trainLabel['Subject'] == name_file.replace('.json', '')]
    # Agregar la columna label e insertar el valor correspondiente
    file.insert(5, 'label', specLabel['label'].values[0])

    for content in file['message']:
        # Convertir las palabras en la fuente general
        tempMessage = ''.join(fontsWords[caracter] if caracter in fontsWords else caracter for caracter in content)

        # Cambiar emoji por texto
        tempMessage = ''.join(emojis[caracter] if caracter in emojis else caracter for caracter in tempMessage)

        # Eliminar signos de puntuacion extraÃ±os, cambiar letra acentuada
        tempMessage = unicodedata.normalize('NFKD', tempMessage).encode('ASCII', 'ignore').decode('utf-8')
        tempMessage = tempMessage.replace('.', ' ').replace('-', ' ')

        # Tokenizar y convertir a minuscula
        tempMessage = word_tokenize(tempMessage.lower())

        # Eliminar stop words
        tempMessage = [tempMessage for tempMessage in tempMessage if tempMessage.lower() not in stop_words]

        # Eliminar signos de puntuacion
        tempMessage = [tempMessage for tempMessage in tempMessage if tempMessage not in string.punctuation]
        tempMessage = [tempMessage for tempMessage in tempMessage if tempMessage not in puntuacion]

        for word in tempMessage:
            if word in wordCount:
                wordCount[word] = wordCount[word] + 1
                wordStrange[word] = name_file
            else:
                wordCount[word] = 1
                wordStrange[word] = name_file

        # Regresar tempMessage a una oracion
        tempMessage = ' '.join(tempMessage)
        # Agregar en la columna preproccedMessage el texto preprocesado
        file.loc[i, 'preproccedMessage'] = tempMessage
        i = i + 1

    # Agregar al dict dataArray los subjects
    dataArray['Subject'].append(name_file.replace('.json', ''))
    dataArray['id_message'].append(file['id_message'])
    dataArray['message'].append(file['message'])
    dataArray['preproccedMessage'].append(file['preproccedMessage'])
    dataArray['date'].append(file['date'])
    dataArray['label'].append(file['label'])

    # TODO agregar signos que no estÃ¡n es string.punctuation


readJSONFiles()

# Convertir a Data Frame y guardar como JSON
finalFile = pd.DataFrame(dataArray.items())
finalFile.to_json(f'{PATH_CSVLINKEDFILES}ab.json')

# Ordenar de mayor a menor las palabras
wordCount = dict(sorted(wordCount.items(), key=lambda item: item[1], reverse=True))
word = list(wordCount.keys())
count = list(wordCount.values())

# Crear una tabla de las palabras tokenizadas y su cantidad
wordCountTab = go.Figure(data=[go.Table(header=dict(values=['Word', 'Count']),
                                        cells=dict(values=[word, count])
                                        )])
# Mostrar tabla
wordCountTab.show()

# Crear Data Frame y guardar CSV de las palabras y su cantidad
df = pd.DataFrame(wordCount.items(), columns=['Palabra', 'Cantidad'])
df.to_csv(f'{PATH_CSVLINKEDFILES}new.csv')
